{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests, coint\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(timeseries):    \n",
    "    test = adfuller(timeseries, autolag='AIC')\n",
    "    result = pd.Series(test[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in test[4].items() :\n",
    "        result['Critical Value (%s)'%key] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nonstationary(result):\n",
    "    if abs(result['Test Statistic']) > abs(result['Critical Value (5%)']):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adf_result(result):\n",
    "    print ('Augmented Dickey-Fuller Unit Root\\nNull Hypothesis : Time Series in Non-Stationary')\n",
    "    print (result[['#Lags Used','Test Statistic','p-value','Critical Value (5%)']])\n",
    "    print(\"At 5% significance level\")\n",
    "    if abs(result['Test Statistic']) > abs(result['Critical Value (5%)']):\n",
    "        print (\"Reject Null Hypothesis - Time Series is Stationary\")\n",
    "    else:\n",
    "        print (\"Failed to Reject Null Hypothesis - Time Series is Non-Stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coint_result(result):\n",
    "    print(\"Engel Granger Cointegration\\nNull Hypothesis : No Cointegration\")\n",
    "    print(\"t-Statistic :\\t\\t\", result[0])\n",
    "    print(\"p-value :\\t\\t\", result[1])\n",
    "    print(\"Critical Value 1% :\\t\", result[2][0])\n",
    "    print(\"Critical Value 5% :\\t\", result[2][1])\n",
    "    print(\"Critical Value 10% :\\t\", result[2][2])\n",
    "    print(\"At 5% significance level\")\n",
    "    if(result[1]<=0.05):\n",
    "        print(\"Reject Null Hypothesis - Cointegration is present\")\n",
    "    else:\n",
    "        print(\"Failed to reject Null Hypothesis - No Cointegration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stationary(timeseries):\n",
    "    diff_timeseries = timeseries.copy(deep=True)\n",
    "    while(is_nonstationary(adf_test(diff_timeseries))):\n",
    "        diff_timeseries = diff_timeseries.diff().dropna()\n",
    "        \n",
    "    return diff_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_granger_result(result):\n",
    "    pvalues = []\n",
    "    for i in result:\n",
    "        pvalues.append(result[i][0]['params_ftest'][1])\n",
    "    best_lag = pvalues.index(min(pvalues))+1\n",
    "    print(\"Granger Causality\")\n",
    "    print(\"Best number of Lags :\\t\", best_lag)\n",
    "    print(\"F-statistic :\\t\", result[best_lag][0]['params_ftest'][0])\n",
    "    print(\"p-value :\\t\", result[best_lag][0]['params_ftest'][1])\n",
    "    print(\"At 5% significance level\")\n",
    "    if(result[best_lag][0]['params_ftest'][1] < 0.05):\n",
    "        print(\"Causality is significant\")\n",
    "    else:\n",
    "        print(\"Causality is insignificant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_country(cntry):\n",
    "    cntrycode = {'ind':'INDIA','pak':'PAKISTAN','sri':'SRI LANKA','saf':'SOUTH AFRICA','bra':'BRAZIL'}\n",
    "    print(cntrycode[cntry],'\\n')\n",
    "    \n",
    "    datadf = pd.read_csv(cntry + '.csv', index_col=\"Series Name\")\n",
    "    df = datadf[[\"M2-LCU\",\"Government-expenditure-US$\",\"GDP-US$\"]].rename(columns={\"M2-LCU\":\"M2\",\"Government-expenditure-US$\":\"GE\",\"GDP-US$\":\"GDP\"})\n",
    "    df = df.dropna().apply(np.log)\n",
    "    \n",
    "    print(\"Broad Money (current US$) (M2)\")\n",
    "    print_adf_result(adf_test(df['M2']))\n",
    "    print('\\n')\n",
    "    print(\"Government Expenditure (current US$) (GE)\")\n",
    "    print_adf_result(adf_test(df['GE']))\n",
    "    print('\\n')\n",
    "    print(\"Gross Domestic Product (current US$) (GDP)\")\n",
    "    print_adf_result(adf_test(df['GDP']))\n",
    "    print('\\n')\n",
    "    \n",
    "    df['M2_s'] = make_stationary(df['M2'])\n",
    "    df['GE_s'] = make_stationary(df['GE'])\n",
    "    df['GDP_s'] = make_stationary(df['GDP'])\n",
    "    \n",
    "    print(\"First Difference - Broad Money (current US$)\")\n",
    "    print_adf_result(adf_test(df['M2_s'].dropna()))\n",
    "    print('\\n')\n",
    "    print(\"First Difference - Government Expenditure (current US$)\")\n",
    "    print_adf_result(adf_test(df['GE_s'].dropna()))\n",
    "    print('\\n')\n",
    "    print(\"First Difference - Gross Domestic Product (current US$)\")\n",
    "    print_adf_result(adf_test(df['GDP_s'].dropna()))\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"Cointegration GDP-M2\")\n",
    "    coint_M2 = coint(df['GDP'], df['M2'], trend='c', maxlag=15)\n",
    "    print_coint_result(coint_M2)\n",
    "    print(\"\\nCointegration GDP-GE\")\n",
    "    coint_GE = coint(df['GDP'], df['GE'], trend='c', maxlag=15)\n",
    "    print_coint_result(coint_GE)\n",
    "    \n",
    "    print(\"\\nCausality from M2 to GDP\")\n",
    "    granger_M2GDP = grangercausalitytests(df[['GDP_s','M2_s']].dropna(), maxlag=15, verbose=False)\n",
    "    print_granger_result(granger_M2GDP)\n",
    "    print(\"\\nCausality from GDP to M2\")\n",
    "    granger_GDPM2 = grangercausalitytests(df[['M2_s','GDP_s']].dropna(), maxlag=15, verbose=False)\n",
    "    print_granger_result(granger_GDPM2)\n",
    "    print(\"\\nCausality from GE to GDP\")\n",
    "    granger_GEGDP = grangercausalitytests(df[['GDP_s','GE_s']].dropna(), maxlag=15, verbose=False)\n",
    "    print_granger_result(granger_GEGDP)\n",
    "    print(\"\\nCausality from GDP to GE\")\n",
    "    granger_GDPGE = grangercausalitytests(df[['GE_s','GDP_s']].dropna(), maxlag=15, verbose=False)\n",
    "    print_granger_result(granger_GDPGE)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout=open(\"results.txt\",\"w\")\n",
    "\n",
    "countries = ['ind','pak','sri','saf','bra']\n",
    "for cntry in countries:\n",
    "    run_country(cntry)\n",
    "\n",
    "sys.stdout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
